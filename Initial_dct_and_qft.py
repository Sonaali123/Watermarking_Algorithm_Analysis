# -*- coding: utf-8 -*-
"""DCT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uHtzutDbbU0WzGr3Y14A1mC9ejrkXsR6
"""

from google.colab import files
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import cv2
import io
import matplotlib.pyplot as plt
import os
from IPython.display import HTML, display

def upload_image():
    print("Please upload an image file (PNG/JPG). Use the file chooser that appears.")
    uploaded = files.upload()
    if not uploaded:
        raise RuntimeError("No file uploaded")
    name = list(uploaded.keys())[0]
    img = Image.open(io.BytesIO(uploaded[name])).convert('RGB')
    return img, name

def render_text_to_image(text, size, font_size=48):
    img = Image.new('L', size, color=0)
    draw = ImageDraw.Draw(img)
    try:
        font = ImageFont.truetype("DejaVuSans.ttf", font_size)
    except Exception:
        font = ImageFont.load_default()

    if hasattr(draw, "textbbox"):
        bbox = draw.textbbox((0, 0), text, font=font)
        w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
    else:
        w, h = draw.textsize(text, font=font)

    pos = ((size[0] - w) // 2, (size[1] - h) // 2)
    draw.text(pos, text, fill=255, font=font)
    return img


def embed_watermark_dct(img_pil, watermark_text="CopyRightVIT", alpha=15):
    img = np.array(img_pil)
    img_ycc = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)
    y_channel = img_ycc[:, :, 0].astype(np.float32)

    h, w = y_channel.shape
    block_size = 8

    # Generate watermark (binary mask)
    watermark_img = render_text_to_image(watermark_text, (w//block_size, h//block_size),
                                         font_size=max(12, int(min(h, w)/32)))
    watermark_arr = np.array(watermark_img).astype(np.float32) / 255.0
    watermark_bin = (watermark_arr > 0.5).astype(np.float32)

    wm_h, wm_w = watermark_bin.shape
    wm_idx = 0

    y_w = y_channel.copy()

    # Process each block
    for i in range(0, h - block_size, block_size):
        for j in range(0, w - block_size, block_size):
            if wm_idx >= wm_h * wm_w:
                break

            block = y_channel[i:i+block_size, j:j+block_size]
            dct_block = cv2.dct(block)

            wm_val = watermark_bin[wm_idx // wm_w, wm_idx % wm_w]
            if wm_val == 1:
                dct_block[4, 4] += alpha
            else:
                dct_block[4, 4] -= alpha

            y_w[i:i+block_size, j:j+block_size] = cv2.idct(dct_block)
            wm_idx += 1

    img_ycc_w = img_ycc.copy()
    img_ycc_w[:, :, 0] = np.clip(y_w, 0, 255)
    img_rgb_w = cv2.cvtColor(img_ycc_w.astype(np.uint8), cv2.COLOR_YCrCb2RGB)

    return Image.fromarray(img_rgb_w), watermark_bin


def extract_watermark_dct(cover_pil, watermarked_pil, alpha=15):
    cover = np.array(cover_pil)
    watermarked = np.array(watermarked_pil)
    cover_ycc = cv2.cvtColor(cover, cv2.COLOR_RGB2YCrCb)[:,:,0].astype(np.float32)
    water_ycc = cv2.cvtColor(watermarked, cv2.COLOR_RGB2YCrCb)[:,:,0].astype(np.float32)

    h, w = cover_ycc.shape
    block_size = 8
    wm_bits = []

    for i in range(0, h - block_size, block_size):
        for j in range(0, w - block_size, block_size):
            block_c = cover_ycc[i:i+block_size, j:j+block_size]
            block_w = water_ycc[i:i+block_size, j:j+block_size]

            dct_c = cv2.dct(block_c)
            dct_w = cv2.dct(block_w)

            diff = dct_w[4, 4] - dct_c[4, 4]
            wm_bits.append(1 if diff > 0 else 0)

    wm_size = int(np.sqrt(len(wm_bits)))
    wm_arr = np.array(wm_bits[:wm_size*wm_size]).reshape((wm_size, wm_size)) * 255
    return Image.fromarray(wm_arr.astype(np.uint8))


# ---- MAIN EXECUTION ----
img_pil, uploaded_name = upload_image()
print(f"Uploaded: {uploaded_name}, image size: {img_pil.size}")

alpha = 15
watermarked_pil, watermark_bin = embed_watermark_dct(img_pil, "CopyRightVIT", alpha=alpha)

out_path = "watermarked_dct_CopyRightVIT.png"
watermarked_pil.save(out_path)
print(f"Watermarked image saved to: {out_path}")

extracted_pil = extract_watermark_dct(img_pil, watermarked_pil, alpha=alpha)

fig, axes = plt.subplots(1,4, figsize=(20,6))
axes[0].imshow(img_pil)
axes[0].set_title("Original")
axes[0].axis('off')
axes[1].imshow(watermark_bin, cmap='gray')
axes[1].set_title("Watermark (binary mask)")
axes[1].axis('off')
axes[2].imshow(watermarked_pil)
axes[2].set_title("Watermarked Image (DCT)")
axes[2].axis('off')
axes[3].imshow(extracted_pil, cmap='gray')
axes[3].set_title("Extracted Watermark")
axes[3].axis('off')
plt.show()

display(HTML(f'<a href="/file={out_path}" target="_blank">Download watermarked image</a>'))
print("If the link does not open, open Colab left sidebar Files and download /mnt/data/watermarked_dct_CopyRightVIT.png")



"""In the DCT method, watermark bits are embedded block by block (8×8). Since the number of blocks is much smaller than your image size, the watermark is downsampled heavily. That’s why you’re only seeing a crude "right" instead of the full "CopyRightVIT" text.

#qft
"""

!pip install qiskit qiskit-aer pillow matplotlib numpy

!pip install qiskit qiskit-aer pillow matplotlib numpy opencv-python

from qiskit import QuantumCircuit
from qiskit_aer import AerSimulator
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import cv2
import io
from google.colab import files

# ---------- Upload Cover Image ----------
def upload_image():
    uploaded = files.upload()
    name = list(uploaded.keys())[0]
    img = Image.open(io.BytesIO(uploaded[name])).convert("RGB")
    return img, name

# ---------- Create Watermark Image ----------
def create_watermark_image(text="COPY", size=(8,8)):
    img = Image.new("L", size, color=0)
    draw = ImageDraw.Draw(img)
    font = ImageFont.load_default()
    bbox = draw.textbbox((0,0), text, font=font)
    pos = ((size[0] - (bbox[2]-bbox[0])) // 2,
           (size[1] - (bbox[3]-bbox[1])) // 2)
    draw.text(pos, text, fill=255, font=font)
    return np.array(img)

# ---------- QFT / IQFT Circuits ----------
def qft_circuit(n):
    qc = QuantumCircuit(n)
    for qubit in range(n):
        qc.h(qubit)
        for k in range(2, n - qubit + 1):
            qc.cp(np.pi / (2**(k-1)), qubit+k-1, qubit)
    for i in range(n//2):
        qc.swap(i, n-i-1)
    return qc

def iqft_circuit(n):
    qc = QuantumCircuit(n)
    for i in range(n//2):
        qc.swap(i, n-i-1)
    for qubit in reversed(range(n)):
        for k in reversed(range(2, n-qubit+1)):
            qc.cp(-np.pi / (2**(k-1)), qubit+k-1, qubit)
        qc.h(qubit)
    return qc

# ---------- Apply Circuit ----------
def apply_circuit(state_vector, circuit):
    n = int(np.log2(len(state_vector)))
    qc = QuantumCircuit(n)
    qc.initialize(state_vector, range(n))
    qc.compose(circuit, inplace=True)
    qc.save_statevector()
    sim = AerSimulator()
    result = sim.run(qc).result()
    return result.get_statevector(0)

# ---------- Embed Watermark ----------
def embed_qft(cover_img, watermark_text="COPY"):
    cover = np.array(cover_img)
    ycc = cv2.cvtColor(cover, cv2.COLOR_RGB2YCrCb)
    Y = ycc[:,:,0].astype(np.float32)

    wm = create_watermark_image(watermark_text, (8,8))
    flat_wm = wm.flatten()/255.0
    # Pad to nearest power of 2 if necessary
    n_qubits = int(np.ceil(np.log2(len(flat_wm))))
    length = 2**n_qubits
    flat_wm = np.pad(flat_wm, (0, length - len(flat_wm)), constant_values=0)
    flat_wm = flat_wm / np.linalg.norm(flat_wm)

    qft_state = apply_circuit(flat_wm, qft_circuit(n_qubits))

    wm_qft_img = np.abs(qft_state[:len(flat_wm)]).reshape(wm.shape)
    wm_resized = cv2.resize(wm_qft_img, (Y.shape[1], Y.shape[0]))
    Y_w = np.clip(Y + 0.2*wm_resized, 0, 255).astype(np.uint8)

    ycc[:,:,0] = Y_w
    watermarked = cv2.cvtColor(ycc, cv2.COLOR_YCrCb2RGB)
    return Image.fromarray(watermarked), wm, qft_state

# ---------- Extract Watermark ----------
def extract_qft(qft_state):
    n_qubits = int(np.log2(len(qft_state)))
    recovered_state = apply_circuit(qft_state, iqft_circuit(n_qubits))
    recovered_img = np.abs(recovered_state[:8*8]).reshape((8,8))
    # Upscale for visibility
    recovered_img_up = cv2.resize(recovered_img, (128,128), interpolation=cv2.INTER_NEAREST)
    return recovered_img_up

# ---------- Run ----------
cover_img, fname = upload_image()
watermarked_img, wm_orig, qft_state = embed_qft(cover_img, "COPY")
recovered_img = extract_qft(qft_state)

# ---------- Display ----------
plt.figure(figsize=(14,5))
plt.subplot(1,3,1)
plt.title("Original Cover")
plt.imshow(cover_img)
plt.axis("off")

plt.subplot(1,3,2)
plt.title("Watermarked Cover")
plt.imshow(watermarked_img)
plt.axis("off")

plt.subplot(1,3,3)
plt.title("Extracted Watermark (Upscaled)")
plt.imshow(recovered_img, cmap="gray")
plt.axis("off")

plt.show()